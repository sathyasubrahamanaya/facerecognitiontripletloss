{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ebd2fc84e5114d44b1f96064da1e4c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c672a5460404b38aa96bd241b53c967",
              "IPY_MODEL_ddfedb09faac49458a1df43ce0ae3332",
              "IPY_MODEL_060ef9ffc63d4e4a93532237a7305fe0"
            ],
            "layout": "IPY_MODEL_c4c50474df5545579e3567bd54fe85fb"
          }
        },
        "0c672a5460404b38aa96bd241b53c967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95f2f5ddad214390864652b88cd6d42c",
            "placeholder": "​",
            "style": "IPY_MODEL_3e647abaca944956a5e62e9e732aca9a",
            "value": "100%"
          }
        },
        "ddfedb09faac49458a1df43ce0ae3332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6442762a9fda4bd28eedd6f07d91b30a",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b369e913ee4448faafb228854227a2c8",
            "value": 111898327
          }
        },
        "060ef9ffc63d4e4a93532237a7305fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8add5d896094124a9cc49df36cbe64e",
            "placeholder": "​",
            "style": "IPY_MODEL_1f75ee080b3c4c1f8fe7b3134be7879a",
            "value": " 107M/107M [00:01&lt;00:00, 98.9MB/s]"
          }
        },
        "c4c50474df5545579e3567bd54fe85fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95f2f5ddad214390864652b88cd6d42c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e647abaca944956a5e62e9e732aca9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6442762a9fda4bd28eedd6f07d91b30a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b369e913ee4448faafb228854227a2c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8add5d896094124a9cc49df36cbe64e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f75ee080b3c4c1f8fe7b3134be7879a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US3Uf_xfnkV_",
        "outputId": "95c4b3bf-bdcd-4f4e-cb1a-698b3383f8fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting facenet-pytorch==2.5.2\n",
            "  Downloading facenet_pytorch-2.5.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch==2.5.2) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch==2.5.2) (2.32.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch==2.5.2) (0.20.1+cu124)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch==2.5.2) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->facenet-pytorch==2.5.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->facenet-pytorch==2.5.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->facenet-pytorch==2.5.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->facenet-pytorch==2.5.2) (2025.1.31)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from torchvision->facenet-pytorch==2.5.2) (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision->facenet-pytorch==2.5.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision->facenet-pytorch==2.5.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1->torchvision->facenet-pytorch==2.5.2) (3.0.2)\n",
            "Downloading facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, facenet-pytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed facenet-pytorch-2.5.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install facenet-pytorch==2.5.2 opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rohanrao619/Face_Recognition_using_Siamese_Network.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QgqPu2yn3Pq",
        "outputId": "c5738d0d-8c2f-4a22-988b-0b2004bb03b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Face_Recognition_using_Siamese_Network'...\n",
            "remote: Enumerating objects: 277, done.\u001b[K\n",
            "remote: Counting objects: 100% (277/277), done.\u001b[K\n",
            "remote: Compressing objects: 100% (275/275), done.\u001b[K\n",
            "remote: Total 277 (delta 21), reused 240 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (277/277), 11.63 MiB | 14.83 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from facenet_pytorch import MTCNN\n",
        "\n",
        "# Set dataset path and desired image size (FaceNet typically uses 160x160)\n",
        "DATA_DIR = '/content/Face_Recognition_using_Siamese_Network/LFW_dataset'  # Update this path to your dataset folder\n",
        "IMG_SIZE = (160, 160)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "mtcnn = MTCNN(image_size=IMG_SIZE, margin=0, device=device)\n",
        "\n",
        "def detect_and_crop_face(image_path, required_size=IMG_SIZE):\n",
        "    \"\"\"\n",
        "    Detects the largest face in the image using MTCNN,\n",
        "    casts bounding box coordinates to integers,\n",
        "    crops the face, and resizes it.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(image_path).convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error loading image: {e}\")\n",
        "    boxes, _ = mtcnn.detect(img)\n",
        "    if boxes is None:\n",
        "        raise Exception(\"No face detected\")\n",
        "    # Use the first detected face\n",
        "    box = boxes[0]\n",
        "    # Cast bounding box coordinates to int\n",
        "    x1, y1, x2, y2 = map(int, box)\n",
        "    # Ensure coordinates are non-negative\n",
        "    x1, y1 = max(0, x1), max(0, y1)\n",
        "    face = img.crop((x1, y1, x2, y2))\n",
        "    face = face.resize(required_size)\n",
        "    return face\n",
        "\n",
        "def load_dataset(data_dir):\n",
        "    faces = []\n",
        "    labels = []\n",
        "    for person in os.listdir(data_dir):\n",
        "        person_folder = os.path.join(data_dir, person)\n",
        "        if not os.path.isdir(person_folder):\n",
        "            continue\n",
        "        for file in os.listdir(person_folder):\n",
        "            file_path = os.path.join(person_folder, file)\n",
        "            try:\n",
        "                face = detect_and_crop_face(file_path)\n",
        "                # Convert image to numpy array in [0,1]\n",
        "                face_np = np.array(face).astype(\"float32\") / 255.0\n",
        "                faces.append(face_np)\n",
        "                labels.append(person)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_path}: {e}\")\n",
        "                continue\n",
        "    return np.array(faces), np.array(labels)\n",
        "\n",
        "faces, labels = load_dataset(DATA_DIR)\n",
        "print(f\"Loaded {faces.shape[0]} faces from {len(np.unique(labels))} identities.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4z9N_n4n5dn",
        "outputId": "df139125-a54e-42a3-8c75-d9ffb3ad0c70"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/facenet_pytorch/models/mtcnn.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(state_dict_path)\n",
            "/usr/local/lib/python3.11/dist-packages/facenet_pytorch/models/mtcnn.py:79: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(state_dict_path)\n",
            "/usr/local/lib/python3.11/dist-packages/facenet_pytorch/models/mtcnn.py:132: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(state_dict_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 200 faces from 20 identities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from facenet_pytorch import InceptionResnetV1\n",
        "\n",
        "# Define a Dataset that yields triplets\n",
        "class TripletFaceDataset(Dataset):\n",
        "    def __init__(self, faces, labels):\n",
        "        self.faces = faces  # numpy array of shape (N, H, W, C)\n",
        "        self.labels = labels  # numpy array of shape (N,)\n",
        "        self.unique_labels = np.unique(labels)\n",
        "        self.label_to_indices = {label: np.where(labels==label)[0] for label in self.unique_labels}\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        anchor_img = self.faces[index]\n",
        "        anchor_label = self.labels[index]\n",
        "        # Positive: choose a different image with the same label\n",
        "        pos_indices = self.label_to_indices[anchor_label]\n",
        "        pos_index = index\n",
        "        while pos_index == index:\n",
        "            pos_index = np.random.choice(pos_indices)\n",
        "        positive_img = self.faces[pos_index]\n",
        "        # Negative: choose an image from a different label\n",
        "        neg_label = np.random.choice(self.unique_labels[self.unique_labels != anchor_label])\n",
        "        neg_index = np.random.choice(self.label_to_indices[neg_label])\n",
        "        negative_img = self.faces[neg_index]\n",
        "\n",
        "        # Convert images to torch tensors and transpose to (C, H, W)\n",
        "        anchor_tensor = torch.tensor(anchor_img.transpose(2,0,1), dtype=torch.float32)\n",
        "        positive_tensor = torch.tensor(positive_img.transpose(2,0,1), dtype=torch.float32)\n",
        "        negative_tensor = torch.tensor(negative_img.transpose(2,0,1), dtype=torch.float32)\n",
        "\n",
        "        return anchor_tensor, positive_tensor, negative_tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.faces)\n",
        "\n",
        "# Create dataset and dataloader\n",
        "triplet_dataset = TripletFaceDataset(faces, labels)\n",
        "dataloader = DataLoader(triplet_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Load the InceptionResnetV1 model (pretrained on VGGFace2)\n",
        "model = InceptionResnetV1(pretrained='vggface2').to(device)\n",
        "model.train()\n",
        "\n",
        "# Define Triplet Margin Loss\n",
        "margin = 0.5\n",
        "criterion = nn.TripletMarginLoss(margin=margin, p=2)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "num_epochs = 20\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    epoch_loss = 0.0\n",
        "    for anchor, positive, negative in dataloader:\n",
        "        # Move data to device and normalize pixel values to [-1, 1]\n",
        "        anchor = ((anchor.to(device)) - 0.5) * 2\n",
        "        positive = ((positive.to(device)) - 0.5) * 2\n",
        "        negative = ((negative.to(device)) - 0.5) * 2\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        emb_anchor = model(anchor)\n",
        "        emb_positive = model(positive)\n",
        "        emb_negative = model(negative)\n",
        "\n",
        "        loss = criterion(emb_anchor, emb_positive, emb_negative)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch}/{num_epochs} - Avg Triplet Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Save the fine-tuned model weights\n",
        "torch.save(model.state_dict(), \"resnet_face_triplet.pth\")\n",
        "print(\"Model saved as resnet_face_triplet.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485,
          "referenced_widgets": [
            "ebd2fc84e5114d44b1f96064da1e4c39",
            "0c672a5460404b38aa96bd241b53c967",
            "ddfedb09faac49458a1df43ce0ae3332",
            "060ef9ffc63d4e4a93532237a7305fe0",
            "c4c50474df5545579e3567bd54fe85fb",
            "95f2f5ddad214390864652b88cd6d42c",
            "3e647abaca944956a5e62e9e732aca9a",
            "6442762a9fda4bd28eedd6f07d91b30a",
            "b369e913ee4448faafb228854227a2c8",
            "f8add5d896094124a9cc49df36cbe64e",
            "1f75ee080b3c4c1f8fe7b3134be7879a"
          ]
        },
        "id": "fMwbGil5ojtk",
        "outputId": "50260374-6ee9-46e0-f8df-c42409eae847"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebd2fc84e5114d44b1f96064da1e4c39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/facenet_pytorch/models/inception_resnet_v1.py:329: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(cached_file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Avg Triplet Loss: 0.0545\n",
            "Epoch 2/20 - Avg Triplet Loss: 0.0449\n",
            "Epoch 3/20 - Avg Triplet Loss: 0.0577\n",
            "Epoch 4/20 - Avg Triplet Loss: 0.0419\n",
            "Epoch 5/20 - Avg Triplet Loss: 0.0362\n",
            "Epoch 6/20 - Avg Triplet Loss: 0.0396\n",
            "Epoch 7/20 - Avg Triplet Loss: 0.0246\n",
            "Epoch 8/20 - Avg Triplet Loss: 0.0434\n",
            "Epoch 9/20 - Avg Triplet Loss: 0.0238\n",
            "Epoch 10/20 - Avg Triplet Loss: 0.0406\n",
            "Epoch 11/20 - Avg Triplet Loss: 0.0276\n",
            "Epoch 12/20 - Avg Triplet Loss: 0.0358\n",
            "Epoch 13/20 - Avg Triplet Loss: 0.0179\n",
            "Epoch 14/20 - Avg Triplet Loss: 0.0453\n",
            "Epoch 15/20 - Avg Triplet Loss: 0.0424\n",
            "Epoch 16/20 - Avg Triplet Loss: 0.0442\n",
            "Epoch 17/20 - Avg Triplet Loss: 0.0293\n",
            "Epoch 18/20 - Avg Triplet Loss: 0.0237\n",
            "Epoch 19/20 - Avg Triplet Loss: 0.0340\n",
            "Epoch 20/20 - Avg Triplet Loss: 0.0444\n",
            "Model saved as resnet_face_triplet.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Cell 3: Evaluation\n",
        "import random\n",
        "model.eval()\n",
        "\n",
        "def compute_distance(emb1, emb2):\n",
        "    return torch.norm(emb1 - emb2, p=2).item()\n",
        "\n",
        "indices = random.sample(range(len(triplet_dataset)), 5)\n",
        "for idx in indices:\n",
        "    anchor, positive, negative = triplet_dataset[idx]\n",
        "    anchor = (((anchor.unsqueeze(0).to(device)) - 0.5) * 2)\n",
        "    positive = (((positive.unsqueeze(0).to(device)) - 0.5) * 2)\n",
        "    negative = (((negative.unsqueeze(0).to(device)) - 0.5) * 2)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        emb_anchor = model(anchor)\n",
        "        emb_positive = model(positive)\n",
        "        emb_negative = model(negative)\n",
        "\n",
        "    pos_dist = compute_distance(emb_anchor, emb_positive)\n",
        "    neg_dist = compute_distance(emb_anchor, emb_negative)\n",
        "    print(f\"Anchor-Positive Distance: {pos_dist:.4f} | Anchor-Negative Distance: {neg_dist:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX7mz3Uxo4EC",
        "outputId": "cb98c7c9-20dc-445f-a752-8d12f94fea8d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anchor-Positive Distance: 0.3884 | Anchor-Negative Distance: 1.4110\n",
            "Anchor-Positive Distance: 0.1939 | Anchor-Negative Distance: 1.7439\n",
            "Anchor-Positive Distance: 0.1887 | Anchor-Negative Distance: 1.6422\n",
            "Anchor-Positive Distance: 0.6721 | Anchor-Negative Distance: 1.3645\n",
            "Anchor-Positive Distance: 0.6129 | Anchor-Negative Distance: 1.7046\n"
          ]
        }
      ]
    }
  ]
}